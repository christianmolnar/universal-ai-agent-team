# Quality Tracking & Analytics System
*Universal Quality Measurement for All Analysis Modules*

**Last Updated:** December 30, 2025  
**Status:** Architecture Design - Ready for Implementation  
**Priority:** CRITICAL - Core system capability

---

## ðŸŽ¯ OVERVIEW

The Quality Tracking & Analytics System is a universal infrastructure that tracks every analysis across all modules (Real Estate, Business, Research, etc.), measuring quality scores, iteration counts, review impact, and user feedback effectiveness. This enables:

1. **Real-time quality monitoring** across all analyses
2. **Trend analysis** to detect quality improvements or regressions
3. **AI-driven insights** to automatically improve system performance
4. **Module comparison** to identify best practices
5. **Self-improvement loops** that make the system better over time

---

## ðŸ—ï¸ ARCHITECTURE PRINCIPLES

### **Universal Design**
- **Domain-agnostic:** Works for any analysis type (Real Estate, Business, Research, Legal, Medical, etc.)
- **Polymorphic references:** No hard foreign keys to specific domain tables
- **JSONB flexibility:** Domain-specific data stored in flexible JSON columns
- **UUID-based linking:** Universal identifiers across all analyses

### **Core Capabilities**
- Track quality scores at every stage (initial, post-review, post-feedback, final)
- Measure iteration counts and timing metrics
- Store improvement triggers and their impact
- Aggregate metrics for fast dashboard queries
- Enable AI pattern detection and recommendations

---

## ðŸ“Š DATABASE SCHEMA

### **Table 1: `universal_analyses`** (Central Registry)

**Purpose:** Central registry of all analyses across all modules

```sql
CREATE TABLE universal_analyses (
  id SERIAL PRIMARY KEY,
  
  -- Universal identifiers
  analysis_uuid UUID UNIQUE NOT NULL DEFAULT gen_random_uuid(),
  module_name VARCHAR(100) NOT NULL, -- 'real-estate', 'business-analysis', 'research', etc.
  analysis_type VARCHAR(100) NOT NULL, -- 'primary-residence', 'investment-property', 'market-research', etc.
  
  -- Polymorphic reference to domain-specific data
  domain_entity_type VARCHAR(100), -- 'property_analyses', 'business_analyses', 'research_reports'
  domain_entity_id INTEGER, -- FK to the specific domain table
  
  -- Analysis metadata
  status VARCHAR(50) NOT NULL DEFAULT 'in_progress', -- 'in_progress', 'completed', 'rejected', 'failed'
  user_id INTEGER, -- References users table (future)
  
  -- Request data (stored as JSONB for flexibility)
  request_data JSONB NOT NULL,
  
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW(),
  completed_at TIMESTAMP
);

-- Indexes for performance
CREATE INDEX idx_universal_analyses_module ON universal_analyses(module_name);
CREATE INDEX idx_universal_analyses_type ON universal_analyses(analysis_type);
CREATE INDEX idx_universal_analyses_status ON universal_analyses(status);
CREATE INDEX idx_universal_analyses_uuid ON universal_analyses(analysis_uuid);
```

**Example Data:**
```json
{
  "analysis_uuid": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
  "module_name": "real-estate",
  "analysis_type": "primary-residence",
  "domain_entity_type": "property_analyses",
  "domain_entity_id": 42,
  "status": "completed",
  "request_data": {
    "zillow_url": "https://zillow.com/...",
    "user_criteria": {
      "min_garage": 3,
      "requires_pool": true,
      "budget": 696000
    }
  }
}
```

---

### **Table 2: `quality_metrics`** (Core Quality Tracking)

**Purpose:** Track quality scores and metrics for every analysis

```sql
CREATE TABLE quality_metrics (
  id SERIAL PRIMARY KEY,
  
  -- Universal reference
  analysis_uuid UUID NOT NULL REFERENCES universal_analyses(analysis_uuid),
  module_name VARCHAR(100) NOT NULL,
  analysis_type VARCHAR(100),
  
  -- Quality scores at each stage
  initial_score INTEGER,
  post_review_score INTEGER,
  post_feedback_score INTEGER,
  final_score INTEGER NOT NULL,
  
  -- Process metrics
  iteration_count INTEGER DEFAULT 0,
  review_count INTEGER DEFAULT 0,
  feedback_count INTEGER DEFAULT 0,
  
  -- Timing metrics (in seconds)
  time_to_quality_threshold_seconds INTEGER,
  total_analysis_time_seconds INTEGER,
  
  -- Quality gate status
  met_threshold BOOLEAN DEFAULT false,
  threshold_value INTEGER DEFAULT 85,
  rejection_reason TEXT,
  
  -- AI model tracking
  primary_model VARCHAR(50), -- 'claude-3.5-sonnet', 'gpt-4', etc.
  review_model VARCHAR(50),
  
  -- Domain-specific metadata (flexible JSONB)
  domain_metadata JSONB, -- Store module-specific quality factors
  
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW()
);

-- Indexes
CREATE INDEX idx_quality_metrics_uuid ON quality_metrics(analysis_uuid);
CREATE INDEX idx_quality_metrics_module ON quality_metrics(module_name);
CREATE INDEX idx_quality_metrics_score ON quality_metrics(final_score);
CREATE INDEX idx_quality_metrics_threshold ON quality_metrics(met_threshold);
```

**Example Data:**
```json
{
  "analysis_uuid": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
  "module_name": "real-estate",
  "analysis_type": "primary-residence",
  "initial_score": 75,
  "post_review_score": 88,
  "post_feedback_score": 95,
  "final_score": 95,
  "iteration_count": 2,
  "review_count": 1,
  "feedback_count": 1,
  "time_to_quality_threshold_seconds": 180,
  "total_analysis_time_seconds": 240,
  "met_threshold": true,
  "threshold_value": 85,
  "primary_model": "claude-3.5-sonnet",
  "review_model": "gpt-4",
  "domain_metadata": {
    "property_address": "123 Main St, Scottsdale AZ",
    "property_price": 1475000,
    "scoring_factors": ["garage", "pool", "lot_size", "casita"]
  }
}
```

---

### **Table 3: `quality_iterations`** (Iteration Details)

**Purpose:** Track each refinement iteration and its impact

```sql
CREATE TABLE quality_iterations (
  id SERIAL PRIMARY KEY,
  quality_metric_id INTEGER REFERENCES quality_metrics(id),
  analysis_uuid UUID NOT NULL REFERENCES universal_analyses(analysis_uuid),
  iteration_number INTEGER NOT NULL,
  
  -- Scores before and after this iteration
  score_before INTEGER NOT NULL,
  score_after INTEGER NOT NULL,
  score_delta INTEGER GENERATED ALWAYS AS (score_after - score_before) STORED,
  
  -- What triggered this iteration
  trigger_type VARCHAR(50) NOT NULL, -- 'auto_review', 'user_feedback', 'refinement_loop', 'quality_gate_failure'
  trigger_content TEXT,
  
  -- Model used
  model_name VARCHAR(50),
  
  -- Changes made (flexible JSONB for any analysis type)
  changes_summary TEXT,
  improvements_applied JSONB, -- Domain-specific improvements
  
  -- Performance metrics
  iteration_duration_seconds INTEGER,
  tokens_used INTEGER,
  
  created_at TIMESTAMP DEFAULT NOW()
);

-- Indexes
CREATE INDEX idx_quality_iterations_uuid ON quality_iterations(analysis_uuid);
CREATE INDEX idx_quality_iterations_metric ON quality_iterations(quality_metric_id);
CREATE INDEX idx_quality_iterations_trigger ON quality_iterations(trigger_type);
```

**Example Data:**
```json
{
  "iteration_number": 1,
  "score_before": 75,
  "score_after": 88,
  "score_delta": 13,
  "trigger_type": "auto_review",
  "trigger_content": "GPT-4 review identified incomplete financial calculations",
  "model_name": "claude-3.5-sonnet",
  "changes_summary": "Added detailed cash flow analysis and property tax calculations",
  "improvements_applied": {
    "added_fields": ["monthly_property_tax", "hoa_fees", "insurance_estimate"],
    "recalculated": ["total_monthly_payment", "affordability_score"]
  },
  "iteration_duration_seconds": 45,
  "tokens_used": 2500
}
```

---

### **Table 4: `user_feedback`** (User Feedback Tracking)

**Purpose:** Track user feedback and its impact on quality

```sql
CREATE TABLE user_feedback (
  id SERIAL PRIMARY KEY,
  analysis_uuid UUID NOT NULL REFERENCES universal_analyses(analysis_uuid),
  quality_metric_id INTEGER REFERENCES quality_metrics(id),
  
  -- User identifier (future)
  user_id INTEGER,
  
  -- Feedback content
  feedback_text TEXT NOT NULL,
  feedback_type VARCHAR(50), -- 'correction', 'enhancement', 'clarification', 'approval', 'rejection'
  
  -- Structured feedback (domain-specific)
  feedback_data JSONB, -- Flexible structure for different modules
  
  -- Impact tracking
  score_before_feedback INTEGER,
  score_after_feedback INTEGER,
  score_improvement INTEGER GENERATED ALWAYS AS (score_after_feedback - score_before_feedback) STORED,
  
  -- Application status
  was_applied BOOLEAN DEFAULT false,
  application_result TEXT,
  applied_at TIMESTAMP,
  
  created_at TIMESTAMP DEFAULT NOW()
);

-- Indexes
CREATE INDEX idx_user_feedback_uuid ON user_feedback(analysis_uuid);
CREATE INDEX idx_user_feedback_type ON user_feedback(feedback_type);
CREATE INDEX idx_user_feedback_applied ON user_feedback(was_applied);
```

**Example Data:**
```json
{
  "feedback_text": "Please recalculate with updated interest rate of 6.5%",
  "feedback_type": "correction",
  "feedback_data": {
    "field": "interest_rate",
    "old_value": 0.07,
    "new_value": 0.065
  },
  "score_before_feedback": 88,
  "score_after_feedback": 95,
  "score_improvement": 7,
  "was_applied": true,
  "application_result": "Successfully recalculated all financial metrics with new rate"
}
```

---

### **Table 5: `module_performance_cache`** (Aggregated Metrics)

**Purpose:** Pre-computed metrics for fast dashboard queries

```sql
CREATE TABLE module_performance_cache (
  id SERIAL PRIMARY KEY,
  module_name VARCHAR(100) NOT NULL,
  analysis_type VARCHAR(100),
  
  -- Time period
  period_start DATE NOT NULL,
  period_end DATE NOT NULL,
  
  -- Aggregated metrics
  total_analyses INTEGER DEFAULT 0,
  successful_analyses INTEGER DEFAULT 0,
  failed_analyses INTEGER DEFAULT 0,
  success_rate DECIMAL(5,2),
  
  -- Quality metrics
  avg_initial_score DECIMAL(5,2),
  avg_final_score DECIMAL(5,2),
  avg_improvement DECIMAL(5,2),
  
  -- Process metrics
  avg_iterations DECIMAL(5,2),
  avg_review_count DECIMAL(5,2),
  avg_feedback_count DECIMAL(5,2),
  
  -- Timing
  avg_time_to_threshold_seconds INTEGER,
  
  -- Impact metrics
  avg_review_impact DECIMAL(5,2),
  avg_feedback_impact DECIMAL(5,2),
  
  last_updated TIMESTAMP DEFAULT NOW(),
  
  UNIQUE(module_name, analysis_type, period_start, period_end)
);

-- Indexes
CREATE INDEX idx_module_performance_module ON module_performance_cache(module_name);
CREATE INDEX idx_module_performance_period ON module_performance_cache(period_start, period_end);
```

---

## ðŸ”— INTEGRATION PATTERNS

### **Real Estate Integration**
```typescript
// When creating property analysis
const universalAnalysis = await db.universalAnalyses.create({
  module_name: 'real-estate',
  analysis_type: 'primary-residence',
  domain_entity_type: 'property_analyses',
  domain_entity_id: propertyAnalysis.id,
  request_data: {
    zillow_url: url,
    user_criteria: criteria
  }
});

// Track quality
await db.qualityMetrics.create({
  analysis_uuid: universalAnalysis.analysis_uuid,
  module_name: 'real-estate',
  analysis_type: 'primary-residence',
  initial_score: 75,
  final_score: 92,
  iteration_count: 2,
  met_threshold: true,
  domain_metadata: {
    property_address: property.address,
    property_price: property.price
  }
});
```

### **Business Analysis Integration (Future)**
```typescript
// Same pattern works for any module!
const universalAnalysis = await db.universalAnalyses.create({
  module_name: 'business-analysis',
  analysis_type: 'market-opportunity',
  domain_entity_type: 'business_analyses',
  domain_entity_id: businessAnalysis.id,
  request_data: {
    company_url: url,
    market_sector: 'SaaS'
  }
});
```

---

## ðŸ“ˆ ANALYTICS CAPABILITIES

### **1. Quality Distribution Query**
```sql
SELECT 
  module_name,
  analysis_type,
  CASE 
    WHEN final_score >= 95 THEN '95-100'
    WHEN final_score >= 90 THEN '90-94'
    WHEN final_score >= 85 THEN '85-89'
    ELSE 'Below 85'
  END as score_range,
  COUNT(*) as count
FROM quality_metrics
WHERE created_at >= NOW() - INTERVAL '30 days'
GROUP BY module_name, analysis_type, score_range
ORDER BY module_name, analysis_type, score_range DESC;
```

### **2. Success Rate by Module**
```sql
SELECT 
  module_name,
  COUNT(*) as total_analyses,
  SUM(CASE WHEN met_threshold THEN 1 ELSE 0 END) as successful,
  ROUND(100.0 * SUM(CASE WHEN met_threshold THEN 1 ELSE 0 END) / COUNT(*), 2) as success_rate_pct
FROM quality_metrics
GROUP BY module_name
ORDER BY success_rate_pct DESC;
```

### **3. Review Impact Analysis**
```sql
SELECT 
  module_name,
  AVG(post_review_score - initial_score) as avg_review_impact,
  COUNT(*) as analyses_with_review
FROM quality_metrics
WHERE post_review_score IS NOT NULL
GROUP BY module_name;
```

### **4. User Feedback Effectiveness**
```sql
SELECT 
  feedback_type,
  COUNT(*) as feedback_count,
  AVG(score_improvement) as avg_improvement,
  SUM(CASE WHEN was_applied THEN 1 ELSE 0 END) as applied_count
FROM user_feedback
WHERE score_improvement > 0
GROUP BY feedback_type
ORDER BY avg_improvement DESC;
```

---

## ðŸ¤– AI-DRIVEN INSIGHTS

### **Pattern Detection Service**
```typescript
class QualityImprovementAI {
  async analyzeQualityPatterns(filters: {
    moduleName?: string;
    analysisType?: string;
    dateRange?: DateRange;
  }): Promise<AIInsights> {
    
    const qualityData = await this.fetchQualityMetrics(filters);
    
    const prompt = `
Analyze these quality metrics from our Universal AI Agent system:

${JSON.stringify(qualityData, null, 2)}

Identify:
1. Common failure patterns
2. Most effective improvement triggers
3. Bottlenecks in the analysis process
4. User feedback patterns
5. Module-specific optimization opportunities

Provide actionable recommendations to improve quality.
`;

    return await this.aiClient.query({ prompt, model: 'claude-3.5-sonnet' });
  }
}
```

---

## ðŸŽ¯ DASHBOARD FEATURES

### **System Overview Panel**
- Current average quality score across all modules
- Success rate (% meeting 85+ threshold)
- Total analyses completed
- Quality score distribution histogram

### **Performance Metrics Panel**
- Average iterations to quality threshold by module
- Review impact (average score increase)
- User feedback impact (average score increase)
- Most common improvement triggers

### **Trends Over Time Panel**
- Quality scores over last 30/60/90 days (line chart)
- Success rate trend
- Iteration count trend
- Feedback volume by week

### **Module Comparison Panel**
- Side-by-side comparison of all modules
- Success rates, average scores, iteration counts
- Best practices identification

---

## ðŸ“‹ IMPLEMENTATION CHECKLIST

### **Phase 1: Database Schema** (1-2 hours)
- [ ] Create migration file for all 5 tables
- [ ] Add indexes for performance
- [ ] Test schema with sample data
- [ ] Create TypeScript types for all tables

### **Phase 2: Service Layer** (2-3 hours)
- [ ] Create `QualityTrackingService`
- [ ] Implement tracking functions for all stages
- [ ] Add helper functions for queries
- [ ] Test with real estate module

### **Phase 3: Analytics Dashboard** (4-5 hours)
- [ ] Create `/analytics` route
- [ ] Build overview panel with key metrics
- [ ] Add filtering capabilities
- [ ] Create trend visualizations

### **Phase 4: AI Insights** (3-4 hours)
- [ ] Create `QualityImprovementAI` service
- [ ] Implement pattern detection
- [ ] Add recommendation generation
- [ ] Build AI insights panel in dashboard

---

## âœ… SUCCESS METRICS

After implementation, the system will enable:

âœ… **Universal quality tracking** across all analysis modules  
âœ… **Real-time monitoring** of system performance  
âœ… **Trend detection** to catch quality regressions early  
âœ… **AI-driven improvements** based on actual performance data  
âœ… **Module comparison** to identify best practices  
âœ… **Self-improving system** that learns from experience  
âœ… **User impact measurement** quantifying value of feedback  

---

**This architecture provides the foundation for a self-improving Universal AI Agent system that gets better over time by learning from its own performance data.**
